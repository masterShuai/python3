1.安装Scrapy 爬虫框架
    先安装wheel ：
        pip install wheel
    验证：
        wheel
    安装相关依赖包：
        pip install parsel
        pip install w3lib
        pip install cryptography
        pip install pyOpenSSL
    lxml和twisted可以在如下网站下载whl文件，之后在安装：http://www.lfd.uci.edu/~gohlke/pythonlibs/
    安装相关依赖包：
        pip install package/lxml-3.6.4-cp35-cp35m-win32.whl #cp35对应python3.5 win32对应32bit
        pip install package/Twisted-16.6.0-cp35-cp35m-win32.whl
    安装scrapy：
        pip install scrapy

2.使用Scrapy抓取正在热映的电影
    创建项目：
        scrapy startproject simpleMovieCrawler
        #[setting.py:配置文件] [__init__.py:无作用，将上级目录变为一个模块] [items.py:定义爬虫需要爬取的项][pipelines.py:处理爬取到的内容]
    建立爬虫：
        scrapy genspider [baiduMovie] https://dianying.nuomi.com/ #在spiders目录下生成[baiduMovie].py文件
    选择爬取项目
        修改items,py
    定义爬取方式
        修改baiduMovie.py
    测试链接是否有效
        scrapy shell https://dianying.nuomi.com
        #建议换个网站，百度会返回http://mdianying.baidu.com/，反之添加步骤 附录①

        若报错 No module named 'win32api' 到上面网站下载pywin32‑220.1‑cp35‑cp35m‑win32.whl
        然后 pip install package/pywin32-220.1-cp35-cp35m-win32.whl
        最后将python安装目录下的"\Lib\site-packages\pywin32_system32"中两个.dll文件，复制到到"\Lib\site-packages\win32"
    保存爬取内容
        修改pipelines.py
    设置pipelines.py来处理最终结果
        在setting.py中添加：ITEM_PIPELINES = {'simpleMovieCrawler.pipelines.SimplemoviecrawlerPipeline':666}
        #666这个数字是决定执行顺序的，因为就一个结果处理器，所以随便填，多个的话，数字越小越优先执行
    运行爬虫
        scrapy crawl baiduMovie


附录①
###：
    为了保证避免被百度搞成移动端，需要修改header的user-Agent
    1.建立中间层：./middlewares文件夹，添加__init__.py、customMiddlewares.py
    2.在customMiddlewares.py中添加：
        #!/usr/bin/env python
        # -*- coding: utf-8 -*-
        from scrapy.contrib.downloadermiddleware.useragent import UserAgentMiddleware

        class CustomUserAgent(UserAgentMiddleware):
            def process_request(self, request, spider):
                ua = "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"
                request.headers.setdefault('User-Agent', ua)
    3.修改settings.py 添加：
        DOWNLOADER_MIDDLEWARES = {
            'simpleMovieCrawler.middlewares.customMiddlewares.CustomUserAgent':3,
            'crapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware':None
        }
###

3.抓取天气预报
     创建项目及爬虫：
        scrapy startproject weather
        scrapy genspider changChunSpider changchun.tianqi.com
     依次修改：
        item.py, changChunSpider.py, pipelines.py, setting.py
     执行：
        scrapy crawl changChunSpider